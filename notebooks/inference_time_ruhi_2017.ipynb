{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb4fd66-58b8-4081-a3bb-1fcb252c0fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huypham/miniconda3/envs/cinc2017/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import warnings\n",
    "\n",
    "import biosppy as bp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (LSTM, Activation, BatchNormalization,\n",
    "                                     Conv1D, Dense, Dropout, Embedding,\n",
    "                                     Flatten, GlobalAveragePooling1D,\n",
    "                                     MaxPooling1D)\n",
    "from tensorflow.keras.models import Sequential, model_from_yaml\n",
    "from tqdm.auto import tqdm\n",
    "import eco2ai\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def preprocess(fp):\n",
    "    name = fp # './' + sys.argv[1] + '.mat'\n",
    "    mat = scipy.io.loadmat(name)\n",
    "\n",
    "    mdata = mat['val']\n",
    "\n",
    "    #print(mdata.shape)\n",
    "    nd = np.asarray([mdata]).flatten()\n",
    "    out = bp.signals.ecg.ecg(signal=nd.astype(float), sampling_rate=300., show=False)\n",
    "\n",
    "    ot = np.asarray(out[1])\n",
    "\n",
    "\n",
    "\n",
    "    length = ot.shape[0]\n",
    "    #print(\"length of filtered signal is\", length)\n",
    "    maxLen = 18286\n",
    "\n",
    "    if (length < maxLen):\n",
    "        diff = maxLen - length\n",
    "        ap = np.concatenate([ot, np.zeros(diff)])\n",
    "    else:\n",
    "        ap = ot[0 : maxLen]\n",
    "\n",
    "    # print(ap.shape[0])\n",
    "    cPD = pd.DataFrame(ap)\n",
    "\n",
    "    la = cPD.diff()\n",
    "    la = la.transpose()\n",
    "    #print (la.shape)\n",
    "    X = la.values.astype(np.float32)\n",
    "\n",
    "    ## Set NaNs to 10e-6\n",
    "    X[np.isnan(X)] = 0\n",
    "\n",
    "    X_train = preprocessing.scale(X, axis=1)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "  def __init__(self, x_data, y_data, batch_size):\n",
    "    self.x, self.y = x_data, y_data\n",
    "    self.batch_size = batch_size\n",
    "    self.num_batches = np.ceil(len(x_data) / batch_size)\n",
    "    self.batch_idx = np.array_split(range(len(x_data)), self.num_batches)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.batch_idx)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[self.batch_idx[idx]]\n",
    "    batch_y = self.y[self.batch_idx[idx]]\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0197fc-3b0c-4c29-b36d-2db8c5c68cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    max_epochs=100\n",
    "    batch_size=32\n",
    "    log_dir='./logs'\n",
    "    debug=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21caea8e-5023-4246-ac0d-ee7ea8d3a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c91c49-6f5e-4c35-b4d0-e9d4c7ba08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 5116/5116 [01:13<00:00, 69.62it/s]\n",
      "val: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1706/1706 [00:24<00:00, 69.42it/s]\n",
      "test: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 1706/1706 [00:24<00:00, 69.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processing time\n",
    "start_processing = time.time()\n",
    "\n",
    "train_df = pd.read_csv('/home/huypham/Projects/ecg/dataset/cinc2017/processed/y_train.csv')\n",
    "val_df = pd.read_csv('/home/huypham/Projects/ecg/dataset/cinc2017/processed/y_val.csv')\n",
    "test_df = pd.read_csv('/home/huypham/Projects/ecg/dataset/cinc2017/processed/y_test.csv')\n",
    "\n",
    "if args.debug:\n",
    "    args.max_epochs = 2\n",
    "    train_df = train_df.sample(args.debug)\n",
    "    val_df = val_df.sample(args.debug)\n",
    "    test_df = test_df.sample(args.debug)\n",
    "\n",
    "\n",
    "train_file = train_df.idx.apply(lambda x: os.path.join('/home/huypham/Projects/ecg/dataset/cinc2017/raw/training', x) + '.mat')\n",
    "val_file = val_df.idx.apply(lambda x: os.path.join('/home/huypham/Projects/ecg/dataset/cinc2017/raw/training', x) + '.mat')\n",
    "test_file = test_df.idx.apply(lambda x: os.path.join('/home/huypham/Projects/ecg/dataset/cinc2017/raw/training', x) + '.mat')\n",
    "\n",
    "\n",
    "train_features = [preprocess(fp) for fp in tqdm(train_file, desc='train')]\n",
    "val_features = [preprocess(fp) for fp in tqdm(val_file, desc='val')]\n",
    "test_features = [preprocess(fp) for fp in tqdm(test_file, desc='test')]\n",
    "\n",
    "X_train = np.concatenate(train_features, axis=0)\n",
    "X_val = np.concatenate(val_features, axis=0)\n",
    "X_test = np.concatenate(test_features, axis=0)\n",
    "\n",
    "y_train = train_df.drop(columns='idx').to_numpy()\n",
    "y_val = val_df.drop(columns='idx').to_numpy()\n",
    "y_test = test_df.drop(columns='idx').to_numpy()\n",
    "\n",
    "train_generator = DataGenerator(X_train, y_train, batch_size=args.batch_size)\n",
    "val_generator = DataGenerator(X_val, y_val, batch_size=args.batch_size)\n",
    "test_generator = DataGenerator(X_test, y_test, batch_size=args.batch_size)\n",
    "\n",
    "end_processing = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b0321c-2dd5-4620-b88f-c2adaf16aa86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5116, 1706, 1706)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train_file), len(val_file), len(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4232b08d-f082-4187-b66b-6f0e5af82be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/huypham/miniconda3/envs/cinc2017/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/huypham/miniconda3/envs/cinc2017/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 22:09:46.575419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-17 22:09:46.579710: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-17 22:09:46.579726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: huypc\n",
      "2023-06-17 22:09:46.579729: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: huypc\n",
      "2023-06-17 22:09:46.579780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 530.41.3\n",
      "2023-06-17 22:09:46.579793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 530.41.3\n",
      "2023-06-17 22:09:46.579797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 530.41.3\n",
      "2023-06-17 22:09:46.579944: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2023-06-17 22:09:46.585397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3001000000 Hz\n",
      "2023-06-17 22:09:46.586014: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22a0f1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-17 22:09:46.586026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 56s 1s/step - loss: 0.4261 - acc: 0.8576 - auc: 0.9671 - f1: 0.8488\n",
      "Test:\n",
      "\tLoss: 0.42606900190865554\n",
      "\tAccuracy: 0.8575615\n",
      "\tAUC: 0.9671117\n",
      "\tF1: 0.84881467\n"
     ]
    }
   ],
   "source": [
    "start_infer = time.time()\n",
    "\n",
    "yaml_file = open(\"/home/huypham/Projects/ecg/tmp/cinc2017_ruhi/model_v6v9_layer_cnn.yaml\", \"r\")\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', 'AUC', f1]\n",
    ")\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_f1', patience=5, verbose=1, mode='max', restore_best_weights=True)\n",
    "best_checkpoint = ModelCheckpoint(os.path.join(args.log_dir, 'model.hdf5'), save_best_only=True, monitor='val_f1', mode='max')\n",
    "tsb = tf.keras.callbacks.TensorBoard(log_dir=args.log_dir)\n",
    "\n",
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     epochs=args.max_epochs,\n",
    "#     validation_data=val_generator,\n",
    "#     callbacks=[early_stopping, best_checkpoint, tsb]\n",
    "# )\n",
    "\n",
    "# import ipdb; ipdb.set_trace()\n",
    "\n",
    "# Load the best\n",
    "model.load_weights('/home/huypham/Projects/ecg/tmp/cinc2017_ruhi/logs/model.hdf5')\n",
    "probs = model.predict(test_generator)\n",
    "labels = np.where(probs > 0.5, 1, 0)\n",
    "# test_f1 = metrics.f1_score(y_test, labels, average='micro')\n",
    "# np.save(os.path.join(args.log_dir, 'test_probs'), probs)\n",
    "\n",
    "test_loss, test_accuracy, test_auc, test_f1 = model.evaluate(test_generator)\n",
    "print('Test:')\n",
    "print('\\tLoss:', test_loss)\n",
    "print('\\tAccuracy:', test_accuracy)\n",
    "print('\\tAUC:', test_auc)\n",
    "print('\\tF1:', test_f1)\n",
    "\n",
    "end_infer = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1e68f9-825a-4a33-927e-6a454372ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time: 0.014379045305735175\n"
     ]
    }
   ],
   "source": [
    "processing_time = (end_processing - start_processing) / (len(train_file) + len(val_file) + len(test_file))\n",
    "print('Processing Time:', processing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f30a722-0877-4f0e-8410-e834110ff7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer Time: 0.06598330158980482\n"
     ]
    }
   ],
   "source": [
    "infer_time = (end_infer - start_infer) / (len(test_file))\n",
    "print('Infer Time:', infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6781055-93ba-42ca-9615-dcdb8fc18b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/huypham/Projects/ecg/tmp/cinc2017_ruhi/y_test_label.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump([y_test, labels], '/home/huypham/Projects/ecg/tmp/cinc2017_ruhi/y_test_label.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a75bddd-6456-40f4-bbeb-a1757c6d791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8264947245017585\n",
      "Specificity: 0.8567247228104179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8264947245017585, 0.8567247228104179)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn import metrics as imetrics\n",
    "def calculate_sensitivity_specificity(y_true, y_pred):\n",
    "    supports = []\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    \n",
    "    for i, label in enumerate(range(y_true.shape[1])):\n",
    "        true = [lbl[i] for lbl in y_true]\n",
    "        pred = [lbl[i] for lbl in y_pred]\n",
    "        supports.append(sum(true))\n",
    "        sensitivity.append(imetrics.sensitivity_score(true, pred))\n",
    "        specificity.append(imetrics.specificity_score(true, pred))\n",
    "\n",
    "    sens = np.average(sensitivity, weights=supports)\n",
    "    spec = np.average(specificity, weights=supports)\n",
    "    print('Sensitivity:', sens)\n",
    "    print('Specificity:', spec)\n",
    "    return sens, spec\n",
    "\n",
    "calculate_sensitivity_specificity(y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f95e9b7-76fe-48e6-bf71-9efee0b7154e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08035"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01437+0.06598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902c3d9-a548-4f53-953e-668301f06b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cinc2017",
   "language": "python",
   "name": "cinc2017"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
